{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This notebook walks your through the process of creating clips with LLM prompts using visual information. \n",
    "\n",
    "Pick a video, decide your prompt, generate a new clip ‚ö°Ô∏è\n",
    "\n",
    "It's as simple as it sounds.\n",
    "\n",
    "If you want to go extra mile you can add Image Overlays or Audio overlays on these clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But first, let's install the dependecies.\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading The Video\n",
    "\n",
    "Before proceeding, ensure access to [VideoDB](https://videodb.io) API key. If not, sign up for API access on the respective platforms.\n",
    "\n",
    "> Get your API key from [VideoDB Console](https://console.videodb.io). ( Free for first 50 uploads, **No credit card required** ) üéâ\n",
    "\n",
    "You can either source a new video from YouTube or select an existing one from your VideoDB collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import videodb\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# TODO: setup .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to VideoDB\n",
    "conn = videodb.connect()\n",
    "coll = conn.get_collection()\n",
    "\n",
    "# TODO: Add video_id if video already exists in the collection\n",
    "video_id = os.getenv(\"VISUAL_DEMO_VIDEO_ID\")\n",
    "video_url = \"https://www.youtube.com/watch?v=7Im2I6STbms\"\n",
    "\n",
    "if not video_id:\n",
    "    video = coll.upload(url=video_url)\n",
    "else:\n",
    "    video = coll.get_video(video_id)\n",
    "\n",
    "print(f\"video_id: {video.id}, name: {video.name}\")\n",
    "video.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing The Visual Information\n",
    "\n",
    "The sample video provided is an episode of Mr. Bean, which relies heavily on visual comedy rather than spoken words. Therefore, visual information is the most effective way to create the clip.\n",
    "\n",
    "Here, you can either provide the `scene_index_id` of the video, if available, or leave it blank to index the video for visual retrieval.\n",
    "\n",
    "To know more about scene indexing click [here](https://docs.videodb.io/scene-index-guide-80).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scene_index_id here if already indexed.\n",
    "scene_index_id = os.getenv(\"VISUAL_DEMO_SCENE_INDEX_ID\")\n",
    "\n",
    "if not scene_index_id:\n",
    "    scene_index_id = video.index_scenes(\n",
    "        extraction_config={\n",
    "            \"threshold\": 20, \n",
    "            \"frame_count\": 3\n",
    "        },\n",
    "        prompt=\"Summarize the essence of the scene in one or two concise sentences without focusing on individual images.\"\n",
    "    )\n",
    "scenes = video.get_scene_index(scene_index_id)\n",
    "print(f\"Video is indexed with scene_index_id {scene_index_id} with {len(scenes)} scenes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting The Indexed Scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene in scenes:\n",
    "    print(f\"{scene['start']}-{scene['end']}: {scene['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Results From Your Prompt\n",
    "\n",
    "The `scene_prompter` function in `video_prompter.py` takes the indexed scenes, chunks them, and then parallelly calls the LLM with user and system prompts to retrieve the desired matching scenes.\n",
    "\n",
    "To create a clip using the `scene_prompter` function from a video, it's crucial to craft a specific prompt that will help identify the most relevant segments for your use case. This prompt should highlight the themes, activity, or specific visual cues you're interested in. \n",
    "\n",
    "The `scene_prompter` will return sentences or segments from the video that match your prompt. Review these to ensure they align with your needs. You can then use these segments to create your clip, focusing on the content that's most relevant to your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_prompter import scene_prompter\n",
    "\n",
    "# This prompt is for finding the iconic copying in examination scene of Mr. Bean\n",
    "user_prompt = \"find the moment where mr.bean is attempting to cheat by peeking over at the answer sheet of man beside him, just find this singular moment with high accuracy.\"\n",
    "result = scene_prompter(scenes, user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate The Clip\n",
    "To generate a clip, first we'll call `get_result_timestamps` from `video_prompter.py` it uses VideoDB's `keyword search` feature. We already leveraged the power of the LLM (Large Language Model) to identify relevant sentences. We'll use the search results to create a programmable video stream. Here's how you can approach this process:\n",
    "\n",
    "We have the descriptions in the `results` variable. We input these keywords into VideoDB's keyword search feature. This function will search through the indexed scenes of your videos to find matches.\n",
    "\n",
    "The search will return a SearchResult object, which contains detailed information about the found segments, including their timestamps, the text of the scene description.\n",
    "\n",
    "**Create a Programmable Video Stream with Timeline**: With the specific segments identified, you can now use `get_clip_timeline` from `video_prompter.py` to get the Timeline to create a new programmable video stream. The Timeline tool allows you to stitch together video segments based on the timestamps provided in the SearchResult object. You can arrange, cut, or combine these segments to craft a fresh video stream that focuses on your topic of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import play_stream\n",
    "from videodb.timeline import Timeline\n",
    "from video_prompter import get_result_timestamps, get_clip_timeline\n",
    "\n",
    "timeline = Timeline(conn)\n",
    "\n",
    "result_timestamps = get_result_timestamps(video, result, scene_index_id=scene_index_id)\n",
    "# Since our requirement is to get only one scene for the meme where Mr. Bean is copying (as specified in the prompt), we set top_n=1.\n",
    "# If you want to retrieve all scenes where copying occurs, you can remove top_n.\n",
    "timeline, duration = get_clip_timeline(video, result_timestamps, timeline, top_n=1) # get timeline of 1st result\n",
    "stream = timeline.generate_stream()\n",
    "play_stream(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream With Text Overlay\n",
    "\n",
    "You can add custom text to the meme for further personalization.\n",
    "\n",
    "For more customization options, refer to the [TextAsset Styling Guide](https://docs.videodb.io/guide-textasset-75)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb.asset import TextStyle\n",
    "from videodb.timeline import TextAsset\n",
    "\n",
    "timeline = Timeline(conn)\n",
    "timeline, duration = get_clip_timeline(video, result_timestamps, timeline, top_n=1)\n",
    "left = TextAsset(\n",
    "    text=\"XXXX\",\n",
    "    duration=duration,\n",
    "    style=TextStyle(\n",
    "        x=190,\n",
    "        y=15,\n",
    "        font = \"Inter\",\n",
    "        fontsize = 25,\n",
    "        fontcolor = \"#002869\",\n",
    "    )\n",
    ")\n",
    "right = TextAsset(\n",
    "    text=\"YYYY\",\n",
    "    duration=duration,\n",
    "    style=TextStyle(\n",
    "        x=420,\n",
    "        y=15,\n",
    "        font = \"Inter\",\n",
    "        fontsize = 25, \n",
    "        fontcolor = \"#00692c\",\n",
    "    )\n",
    ")\n",
    "timeline.add_overlay(0, left)\n",
    "timeline.add_overlay(0, right)\n",
    "stream = timeline.generate_stream()\n",
    "play_stream(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream With Image Overlay \n",
    "\n",
    "You can also add image overlays if needed. For more details, refer to the [Dynamic Video Stream Guide](https://docs.videodb.io/dynamic-video-stream-guide-44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb.asset import TextStyle, ImageAsset\n",
    "from videodb import MediaType\n",
    "\n",
    "timeline = Timeline(conn)\n",
    "timeline, duration = get_clip_timeline(video, result_timestamps, timeline, top_n=1)\n",
    "\n",
    "image1_id = os.getenv(\"VISUAL_DEMO_IMAGE_1\")\n",
    "if not image1_id:\n",
    "    image1_url = \"https://upload.wikimedia.org/wikipedia/sco/thumb/d/d1/Ferrari-Logo.svg/344px-Ferrari-Logo.svg.png\"\n",
    "    image1 = coll.upload(url=image1_url, media_type=MediaType.image)\n",
    "    image1_id = image1.id\n",
    "    print(f\"image1_id: {image1_id}\")\n",
    "\n",
    "image2_id = os.getenv(\"VISUAL_DEMO_IMAGE_2\")\n",
    "if not image2_id:\n",
    "    image2_url = \"https://upload.wikimedia.org/wikipedia/en/thumb/6/66/McLaren_Racing_logo.svg/512px-McLaren_Racing_logo.svg.png\"\n",
    "    image2 = coll.upload(url=image2_url, media_type=MediaType.image)\n",
    "    image2_id = image2.id\n",
    "    print(f\"image2_id: {image2_id}\")\n",
    "\n",
    "left = ImageAsset(\n",
    "    asset_id=image1_id,\n",
    "    duration=duration,\n",
    "    width=70,\n",
    "    height=124,\n",
    "    x=150,\n",
    "    y=200,\n",
    ")\n",
    "right = ImageAsset(\n",
    "    asset_id=image2_id,\n",
    "    duration=duration,\n",
    "    width=128,\n",
    "    height=40,\n",
    "    x=400,\n",
    "    y=240\n",
    ")\n",
    "\n",
    "timeline.add_overlay(0, left)\n",
    "timeline.add_overlay(0, right)\n",
    "stream = timeline.generate_stream()\n",
    "play_stream(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Prompt With Simple Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"find all the car gags with high accuracy\"\n",
    "result = scene_prompter(scenes, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = Timeline(conn)\n",
    "result_timestamps = get_result_timestamps(video, result, scene_index_id=scene_index_id)\n",
    "timeline, duration  = get_clip_timeline(video, result_timestamps, timeline)\n",
    "stream = timeline.generate_stream()\n",
    "play_stream(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have any questions or feedback. Feel free to reach out to us üôåüèº\n",
    "\n",
    "* [Discord](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fdiscord.gg%2Fpy9P639jGz)\n",
    "* [GitHub](https://github.com/video-db)\n",
    "* [Website](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fvideodb.io)\n",
    "* [Email](ashu@videodb.io)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
