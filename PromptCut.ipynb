{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the video prompter from cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_prompter import get_video, video_prompter\n",
    "from videodb import play_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from videodb import play_stream\n",
    "from video_prompter import get_video, video_prompter, get_connection\n",
    "from dotenv import load_dotenv\n",
    "from videodb.timeline import Timeline, VideoAsset, AudioAsset\n",
    "from videodb import MediaType\n",
    "import os\n",
    "\n",
    "# TODO: setup .env file\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv('OPENAI_API_KEY')\n",
    "conn = get_connection()\n",
    "\n",
    "### ----- Upload a fresh video --------- #####\n",
    "def fresh_video(url):\n",
    "    video = conn.upload(url)\n",
    "    #index spoken content in the video\n",
    "    video.index_spoken_words()\n",
    "    return video\n",
    "\n",
    "#### ------ Pick exisiting video from your VideoDB --------####\n",
    "def videodb_prompter(video_id, prompt):\n",
    "    video = get_video(video_id)\n",
    "    #get all the segment of videos that are\n",
    "    return video_prompter(video, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide your prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8twtL6K6sZlcQDypoDKQiYvqtcMbz', 'object': 'chat.completion', 'created': 1708345111, 'model': 'gpt-3.5-turbo-16k-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\\n  \"timestamps\": [\\n    {\\n      \"s\": 997.5,\\n      \"e\": 1003.9\\n    },\\n    {\\n      \"s\": 1003.4,\\n      \"e\": 1018.8\\n    },\\n    {\\n      \"s\": 1018.5,\\n      \"e\": 1029.6\\n    },\\n    {\\n      \"s\": 1028.0,\\n      \"e\": 1038.6\\n    },\\n    {\\n      \"s\": 1038.2,\\n      \"e\": 1046.2\\n    },\\n    {\\n      \"s\": 1045.9,\\n      \"e\": 1058.4\\n    },\\n    {\\n      \"s\": 1055.6,\\n      \"e\": 1063.2\\n    },\\n    {\\n      \"s\": 1063.1,\\n      \"e\": 1086.4\\n    },\\n    {\\n      \"s\": 1086.4,\\n      \"e\": 1087.0\\n    },\\n    {\\n      \"s\": 1086.4,\\n      \"e\": 1095.7\\n    },\\n    {\\n      \"s\": 1095.4,\\n      \"e\": 1107.7\\n    },\\n    {\\n      \"s\": 1107.3,\\n      \"e\": 1112.2\\n    },\\n    {\\n      \"s\": 1112.1,\\n      \"e\": 1124.7\\n    },\\n    {\\n      \"s\": 1124.4,\\n      \"e\": 1133.8\\n    },\\n    {\\n      \"s\": 1133.6,\\n      \"e\": 1144.1\\n    },\\n    {\\n      \"s\": 1143.7,\\n      \"e\": 1156.0\\n    },\\n    {\\n      \"s\": 1155.9,\\n      \"e\": 1166.5\\n    },\\n    {\\n      \"s\": 1166.2,\\n      \"e\": 1180.1\\n    },\\n    {\\n      \"s\": 1180.1,\\n      \"e\": 1189.9\\n    },\\n    {\\n      \"s\": 1189.7,\\n      \"e\": 1200.8\\n    },\\n    {\\n      \"s\": 1200.8,\\n      \"e\": 1215.9\\n    },\\n    {\\n      \"s\": 1215.9,\\n      \"e\": 1220.2\\n    },\\n    {\\n      \"s\": 1220.2,\\n      \"e\": 1220.7\\n    },\\n    {\\n      \"s\": 1220.2,\\n      \"e\": 1240.1\\n    },\\n    {\\n      \"s\": 1240.1,\\n      \"e\": 1240.5\\n    },\\n    {\\n      \"s\": 1240.1,\\n      \"e\": 1260.1\\n    },\\n    {\\n      \"s\": 1260.1,\\n      \"e\": 1270.4\\n    },\\n    {\\n      \"s\": 1270.4,\\n      \"e\": 1277.5\\n    },\\n    {\\n      \"s\": 1277.0,\\n      \"e\": 1290.3\\n    },\\n    {\\n      \"s\": 1289.1,\\n      \"e\": 1299.8\\n    },\\n    {\\n      \"s\": 1299.5,\\n      \"e\": 1303.8\\n    },\\n    {\\n      \"s\": 1303.6,\\n      \"e\": 1315.7\\n    },\\n    {\\n      \"s\": 1315.5,\\n      \"e\": 1327.2\\n    },\\n    {\\n      \"s\": 1326.9,\\n      \"e\": 1334.7\\n    },\\n    {\\n      \"s\": 1334.2,\\n      \"e\": 1345.2\\n    },\\n    {\\n      \"s\": 1343.4,\\n      \"e\": 1360.1\\n    },\\n    {\\n      \"s\": 1359.7,\\n      \"e\": 1369.0\\n    },\\n    {\\n      \"s\": 1368.7,\\n      \"e\": 1380.1\\n    },\\n    {\\n      \"s\": 1379.9,\\n      \"e\": 1386.1\\n    },\\n    {\\n      \"s\": 1385.9,\\n      \"e\": 1399.7\\n    },\\n    {\\n      \"s\": 1399.5,\\n      \"e\": 1408.5\\n    },\\n    {\\n      \"s\": 1408.4,\\n      \"e\": 1419.8\\n    },\\n    {\\n      \"s\": 1419.7,\\n      \"e\": 1428.2\\n    },\\n    {\\n      \"s\": 1427.9,\\n      \"e\": 1433.9\\n    },\\n    {\\n      \"s\": 1433.8,\\n      \"e\": 1449.3\\n    },\\n    {\\n      \"s\": 1449.0,\\n      \"e\": 1453.8\\n    },\\n    {\\n      \"s\": 1453.6,\\n      \"e\": 1467.6\\n    },\\n    {\\n      \"s\": 1467.1,\\n      \"e\": 1479.5\\n    },\\n    {\\n      \"s\": 1479.3,\\n      \"e\": 1485.6\\n    },\\n    {\\n      \"s\": 1485.5,\\n      \"e\": 1501.0\\n    },\\n    {\\n      \"s\": 1501.0,\\n      \"e\": 1513.1\\n    },\\n    {\\n      \"s\": 1513.1,\\n      \"e\": 1520.2\\n    },\\n    {\\n      \"s\": 1520.2,\\n      \"e\": 1526.1\\n    },\\n    {\\n      \"s\": 1525.8,\\n      \"e\": 1542.0\\n    }\\n  ]\\n}'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 2647, 'completion_tokens': 1304, 'total_tokens': 3951}, 'system_fingerprint': None}\n",
      "{'id': 'chatcmpl-8twtLf9pnzwsgApsc35fBUV6eMSGg', 'object': 'chat.completion', 'created': 1708345111, 'model': 'gpt-3.5-turbo-16k-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\\n  \"timestamps\": [\\n    {\"s\": 0, \"e\": 9.2},\\n    {\"s\": 8.8, \"e\": 16.9},\\n    {\"s\": 44.9, \"e\": 53.0},\\n    {\"s\": 52.8, \"e\": 66.0},\\n    {\"s\": 66.0, \"e\": 82.2},\\n    {\"s\": 83.5, \"e\": 100.0},\\n    {\"s\": 100.0, \"e\": 103.7},\\n    {\"s\": 118.8, \"e\": 130.0},\\n    {\"s\": 148.8, \"e\": 156.7},\\n    {\"s\": 156.2, \"e\": 175.2},\\n    {\"s\": 178.6, \"e\": 184.5},\\n    {\"s\": 184.4, \"e\": 195.6},\\n    {\"s\": 195.4, \"e\": 206.1},\\n    {\"s\": 214.3, \"e\": 225.6},\\n    {\"s\": 225.4, \"e\": 236.1},\\n    {\"s\": 235.9, \"e\": 249.1},\\n    {\"s\": 246.9, \"e\": 264.0},\\n    {\"s\": 264.0, \"e\": 271.0},\\n    {\"s\": 271.0, \"e\": 279.7},\\n    {\"s\": 279.5, \"e\": 290.5},\\n    {\"s\": 290.5, \"e\": 300.0},\\n    {\"s\": 307.0, \"e\": 313.6},\\n    {\"s\": 313.0, \"e\": 328.8},\\n    {\"s\": 328.7, \"e\": 336.4},\\n    {\"s\": 336.0, \"e\": 343.7},\\n    {\"s\": 343.4, \"e\": 357.8},\\n    {\"s\": 376.5, \"e\": 381.2},\\n    {\"s\": 381.2, \"e\": 387.6},\\n    {\"s\": 386.4, \"e\": 402.0},\\n    {\"s\": 410.5, \"e\": 411.1},\\n    {\"s\": 410.7, \"e\": 422.4},\\n    {\"s\": 422.2, \"e\": 439.6},\\n    {\"s\": 439.1, \"e\": 443.6},\\n    {\"s\": 443.2, \"e\": 451.7},\\n    {\"s\": 451.3, \"e\": 472.1},\\n    {\"s\": 472.1, \"e\": 472.7},\\n    {\"s\": 472.3, \"e\": 486.8},\\n    {\"s\": 515.5, \"e\": 516.8},\\n    {\"s\": 520.3, \"e\": 522.8},\\n    {\"s\": 522.2, \"e\": 539.7},\\n    {\"s\": 539.3, \"e\": 549.0},\\n    {\"s\": 570.0, \"e\": 570.6},\\n    {\"s\": 593.7, \"e\": 599.3},\\n    {\"s\": 607.9, \"e\": 621.9},\\n    {\"s\": 621.9, \"e\": 631.8},\\n    {\"s\": 629.7, \"e\": 638.1},\\n    {\"s\": 637.5, \"e\": 649.3},\\n    {\"s\": 649.2, \"e\": 663.7},\\n    {\"s\": 680.0, \"e\": 689.3},\\n    {\"s\": 689.0, \"e\": 692.3},\\n    {\"s\": 711.9, \"e\": 720.1},\\n    {\"s\": 720.1, \"e\": 727.8},\\n    {\"s\": 727.5, \"e\": 737.1},\\n    {\"s\": 736.9, \"e\": 748.6},\\n    {\"s\": 762.8, \"e\": 770.0},\\n    {\"s\": 780.6, \"e\": 782.0},\\n    {\"s\": 790.4, \"e\": 815.2},\\n    {\"s\": 815.2, \"e\": 823.7},\\n    {\"s\": 823.7, \"e\": 829.4},\\n    {\"s\": 829.2, \"e\": 838.3},\\n    {\"s\": 837.6, \"e\": 849.8},\\n    {\"s\": 849.4, \"e\": 857.1},\\n    {\"s\": 856.8, \"e\": 869.5},\\n    {\"s\": 869.4, \"e\": 880.0},\\n    {\"s\": 881.4, \"e\": 893.7},\\n    {\"s\": 893.6, \"e\": 916.5},\\n    {\"s\": 916.5, \"e\": 920.2},\\n    {\"s\": 920.2, \"e\": 921.6},\\n    {\"s\": 920.9, \"e\": 941.3},\\n    {\"s\": 939.2, \"e\": 949.3},\\n    {\"s\": 949.0, \"e\": 954.9},\\n    {\"s\": 954.1, \"e\": 964.0},\\n    {\"s\": 963.8, \"e\": 978.6},\\n    {\"s\": 978.3, \"e\": 987.7}\\n  ]\\n}'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 4210, 'completion_tokens': 1265, 'total_tokens': 5475}, 'system_fingerprint': None}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"find the moments useful for social media trailer for this video\"\n",
    "\n",
    "# Existing video case\n",
    "# TODO: replace with your video id\n",
    "# video_id = \"m-replace-with-your-video-id-24-7\"\n",
    "\n",
    "# Fresh video case\n",
    "# url = \"\"\n",
    "# video = fresh_video(url)\n",
    "# video_id = video.id\n",
    "\n",
    "timestamps = videodb_prompter(video_id, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank your results\n",
    "\n",
    "You can control the time, quality etc. of each chunk selected. We are using a very simple critaria here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_timestamps(timestamps):\n",
    "    \"\"\"\n",
    "    Sort, reject, and merge timestamp chunks based on specified criteria.\n",
    "    - Reject chunks with identical start and end times or where start is greater than end.\n",
    "    - Discard chunks shorter than 5 seconds.\n",
    "    - Merge overlapping chunks.\n",
    "    :param timestamps: List of timestamp dictionaries with 's' and 'e' as keys.\n",
    "    :return: List of tuples representing the merged and filtered timeline.\n",
    "    \"\"\"\n",
    "    # Filter out invalid timestamps.\n",
    "    filtered_timestamps = [ts for ts in timestamps if ts['s'] < ts['e'] and (ts['e'] - ts['s']) >= 5]\n",
    "\n",
    "    # Sort the timestamps by start time.\n",
    "    sorted_timestamps = sorted(filtered_timestamps, key=lambda x: x['s'])\n",
    "\n",
    "    if len(sorted_timestamps) == 0:\n",
    "        return []\n",
    "\n",
    "    # Initialize the stack with the first timestamp.\n",
    "    stack = [sorted_timestamps[0]]\n",
    "\n",
    "    # Iterate over the rest of the timestamps.\n",
    "    for i in range(1, len(sorted_timestamps)):\n",
    "        top = stack[-1]\n",
    "\n",
    "        # Check for overlap with the top of the stack; merge if necessary.\n",
    "        if sorted_timestamps[i]['s'] <= top['e']:\n",
    "            merged_end = max(top['e'], sorted_timestamps[i]['e'])\n",
    "            stack[-1] = {'s': top['s'], 'e': merged_end}  # Update the top element with the merged time.\n",
    "        else:\n",
    "            stack.append(sorted_timestamps[i])  # No overlap; add to the stack.\n",
    "\n",
    "    # Convert to list of tuples for the return value.\n",
    "    merged_timeline = [(item['s'], item['e']) for item in stack]\n",
    "    return merged_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(997.5, 1107.7),\n",
       " (1112.1, 1215.9),\n",
       " (1220.2, 1299.8),\n",
       " (1303.6, 1449.3),\n",
       " (1453.6, 1542.0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_timestamps(timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the order and generate stream\n",
    "\n",
    "Here we generated the new timeline, in same order as the sorted timestamps, we didn't drop any of the segment and didn't verify it but you should use your own logic to decide on order of adding them inline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = Timeline(conn)\n",
    "dur_so_far = 0\n",
    "for segment in process_timestamps(timestamps):\n",
    "    # here you can rank each asset again for your prompt and decide order,\n",
    "    video_asset = VideoAsset(asset_id=video_id, start=segment[0], end=segment[1])\n",
    "    timeline.add_inline(video_asset)\n",
    "    dur_so_far += (segment[1] - segment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.videodb.io/player?url=https://stream.videodb.io/v3/published/manifests/93b9cb43-6747-4a1b-95aa-46cbd715ae86.m3u8'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = timeline.generate_stream()\n",
    "play_stream(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some sound effects to it 🎶\n",
    "\n",
    "Not just this we can jazz it up with audio overlays and create another stream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add music overlay, this can be laughter soundtrack\n",
    "audio = conn.upload(file_path=\"laughter_sound.mp3\", media_type=MediaType.audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 sec background music\n",
    "background = AudioAsset(asset_id=audio.id, start=0, disable_other_tracks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = Timeline(conn)\n",
    "dur_so_far = 0\n",
    "for segment in process_timestamps(timestamps_):\n",
    "    # here you can rank each asset again for your prompt and decide order,\n",
    "    video_asset = VideoAsset(asset_id=video_id, start=segment[0], end=segment[1])\n",
    "    timeline.add_inline(video_asset)\n",
    "    dur_so_far += (segment[1] - segment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.videodb.io/player?url=https://stream.videodb.io/v3/published/manifests/9e10504f-b2b0-4fec-8efb-22075d68338c.m3u8'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add music overlay in the last 2 sec of the supercut.\n",
    "timeline.add_overlay(20,background)\n",
    "stream = timeline.generate_stream()\n",
    "play_stream(stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
